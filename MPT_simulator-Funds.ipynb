{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## IMPORT NECESSARY LIBRARIES \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as npg\n",
    "from autograd import grad, elementwise_grad as e_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, CrosshairTool, HoverTool, NumeralTickFormatter, Span, DatetimeTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column, row, gridplot, layout\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.colors import RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime,date\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import bankroll\n",
    "import colorsys\n",
    "# import cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, minimize_scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_profiles = 5000\n",
    "inflation_rate = 0.06\n",
    "\n",
    "start_date = '2000-06-01 00:00:00'\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 'MAX'\n",
    "MIN = 'MIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_names = [\n",
    "    \"Roth IRA\",\n",
    "    \"Investment Account\",\n",
    "    \"Amazon \",\n",
    "    \"Cash Account\",\n",
    "]\n",
    "profiles_targets:List[Tuple[float, float]] = [ \n",
    "    # Tuples are risk, return\n",
    "    (0.10, MAX),\n",
    "    None,\n",
    "    (0.20, MAX),\n",
    "    None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw, self.v_dw = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, t, w, dw):\n",
    "        self.m_dw = np.add(np.multiply(self.beta1,self.m_dw),np.multiply((1-self.beta1), dw))\n",
    "\n",
    "        self.v_dw = np.add(np.multiply(self.beta2, self.v_dw), np.multiply((1-self.beta2),np.square(dw)))\n",
    "\n",
    "        m_dw_corr = np.divide(self.m_dw,np.subtract((1+self.epsilon),np.power(self.beta1,t)))\n",
    "        v_dw_corr = np.divide(self.v_dw,np.subtract((1+self.epsilon),np.power(self.beta2,t)))\n",
    "\n",
    "        w = np.subtract(w, np.multiply(self.eta, np.divide(m_dw_corr, np.add(np.sqrt(v_dw_corr), self.epsilon))))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.sum(x)\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def tanh_refined(x):\n",
    "    return (np.tanh(x)+1.0)/2.0\n",
    "\n",
    "def get_weights(wts):\n",
    "#     wts = sigmoid(wts)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts)\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterTickers(ticks, tick_allowed):\n",
    "    return [tick for tick, allowed in zip(ticks, tick_allowed) if allowed]\n",
    "\n",
    "def get_return(wts):\n",
    "    wts = np.array(wts)\n",
    "#     wts = get_weights(wts)\n",
    "    port_ret = npg.sum(log_ret_mean * wts)\n",
    "    port_ret = np.exp(port_ret*252) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk(wts):\n",
    "    wts = np.array(wts)\n",
    "#     wts = get_weights(wts)\n",
    "    port_sd = npg.sqrt(npg.dot(wts.T, npg.dot(cov_mat, wts)))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe(wts):\n",
    "    port_ret = get_return(wts)\n",
    "    port_sd = get_risk(wts)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_v(wts):\n",
    "#     wts = sigmoid(wts)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts, axis=1, keepdims=True)\n",
    "    return wts\n",
    "\n",
    "def get_return_v(wts):\n",
    "    wts = get_weights_v(wts)\n",
    "    port_ret = npg.sum(log_ret_mean * wts, axis=1)\n",
    "    port_ret = npg.exp(npg.multiply(port_ret, 252)) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk_v(wts):\n",
    "    wts = get_weights_v(wts)\n",
    "    port_sd = npg.sqrt(npg.sum(wts * npg.dot(wts, cov_mat.T), axis=1))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe_v(wts):\n",
    "    port_ret = get_return_v(wts)\n",
    "    port_sd = get_risk_v(wts)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For adding cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_ratio(wts_1, wts_2, ratio):\n",
    "    wts_1 = np.array(wts_1)\n",
    "    wts_2 = np.array(wts_2)\n",
    "    wts = wts_1 * ratio + wts_2 * (1.0 - ratio)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts)\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterTickers(ticks, tick_allowed):\n",
    "    return [tick for tick, allowed in zip(ticks, tick_allowed) if allowed]\n",
    "\n",
    "def get_return_ratio(wts_1,wts_2,ratio):\n",
    "    wts = get_weights_ratio(wts_1,wts_2,ratio)\n",
    "    port_ret = npg.sum(log_ret_mean * wts)\n",
    "    port_ret = np.exp(port_ret*252) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk_ratio(wts_1,wts_2,ratio):\n",
    "    wts = get_weights_ratio(wts_1,wts_2,ratio)\n",
    "    port_sd = npg.sqrt(npg.dot(wts.T, npg.dot(cov_mat, wts)))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe_ratio(wts_1,wts_2,ratio):\n",
    "    port_ret = get_return_ratio(wts_1,wts_2,ratio)\n",
    "    port_sd = get_risk_ratio(wts_1,wts_2,ratio)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_gd_weights(weights_size, loss_fun, batch, iterations, LR, scorings, initial=None):\n",
    "    # Optimize weights using gradient descent.\n",
    "    if initial is not None:\n",
    "        best_weights = get_weights(initial) + np.random.uniform(size=weights_size)\n",
    "    else:\n",
    "        best_weights = np.random.uniform(size=weights_size)\n",
    "    training_gradient_fun = grad(loss_fun)\n",
    "    scores = np.zeros((len(scorings), batch, iterations))\n",
    "    for b in range(batch):\n",
    "        if initial is not None:\n",
    "            wts = get_weights(initial) + np.random.uniform(size=weights_size)\n",
    "        else:\n",
    "            wts = np.random.uniform(size=weights_size)\n",
    "        for i in range(iterations):\n",
    "            wts = wts - training_gradient_fun(wts) * LR\n",
    "            for s in range(len(scorings)):\n",
    "                scores[s, b, i] = scorings[s](wts)\n",
    "        if loss_fun(wts) < loss_fun(best_weights):\n",
    "            best_weights = wts\n",
    "    return best_weights, scores\n",
    "\n",
    "def calculate_weights(weights_size, loss_fun_v, batch, iterations, LR, scorings, initial=None):\n",
    "    adam = AdamOptim(eta=LR)\n",
    "    training_gradient_fun_v = e_grad(loss_fun_v)\n",
    "    scores = np.zeros((len(scorings), batch, iterations))\n",
    "    wts = np.random.uniform(size=(batch, weights_size))*4\n",
    "    print(wts.shape)\n",
    "    for i in range(iterations):\n",
    "        dw = training_gradient_fun_v(wts)\n",
    "        wts = adam.update(i+1,wts, dw)\n",
    "        for s in range(len(scorings)):\n",
    "            scores[s, :, i] = scorings[s](wts)\n",
    "    best_weights = wts[np.argmin(loss_fun_v(wts)),:]\n",
    "    return best_weights, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_vs_return(risk, returns, risk_title=\"Risk\", return_title=\"Return\"):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].plot(risk.T)\n",
    "    ax[0].set_title(risk_title)\n",
    "    ax[1].plot(returns.T)\n",
    "    ax[1].set_title(return_title)\n",
    "    \n",
    "    ax[0].set_ylabel('Risk')\n",
    "    ax[0].set_xlabel('Iteration')\n",
    "    ax[1].set_ylabel('Return')\n",
    "    ax[1].set_xlabel('Iteration')\n",
    "    plt.show()\n",
    "\n",
    "    # Portfolio composition. Min variance, max SR, max return\n",
    "def plot_portfolio_composition(ticks, weights, plot_name, color_list, cash=None):\n",
    "    x = dict()\n",
    "    c = dict()\n",
    "    for i in range(len(ticks)):\n",
    "        if weights[i] >= 0.95:\n",
    "            if cash:\n",
    "                x[ticks[i]] = weights[i] * (cash)\n",
    "                c[ticks[i]] = color_list[i]\n",
    "                x[ticks[i]+\" \"] = weights[i] * (cash)\n",
    "                c[ticks[i]+\" \"] = color_list[i]\n",
    "            else:\n",
    "                x[ticks[i]] = weights[i]\n",
    "                c[ticks[i]] = color_list[i]\n",
    "                x[ticks[i]+\" \"] = weights[i]\n",
    "                c[ticks[i]+\" \"] = color_list[i]\n",
    "        elif weights[i] > 0.001:\n",
    "            if cash:\n",
    "                x[ticks[i]] = weights[i] * (cash)\n",
    "                c[ticks[i]] = color_list[i]\n",
    "            else:\n",
    "                x[ticks[i]] = weights[i]\n",
    "                c[ticks[i]] = color_list[i]\n",
    "\n",
    "    plot_data = pd.Series(x).reset_index(name='value').rename(columns={'index': 'stock'})\n",
    "    plot_data['angle'] = plot_data['value'] / plot_data['value'].sum() * 2 * math.pi\n",
    "    \n",
    "    plot_data['color'] = c.values()\n",
    "    \n",
    "    if cash:\n",
    "        p = figure(width=50, height=50, title=plot_name, toolbar_location=None,sizing_mode = \"scale_height\",\n",
    "                      tools=\"hover\", tooltips=\"@stock: $@value{0,0.00} \", x_range=(-0.5,0.5))\n",
    "    else:\n",
    "        p = figure(width=50, height=50, title=plot_name, toolbar_location=None,sizing_mode = \"scale_height\",\n",
    "                      tools=\"hover\", tooltips=\"@stock: @value{%0.1f}\", x_range=(-0.5,0.5))\n",
    "    p.title.align = 'center'\n",
    "    p.wedge(x=0, y=1, radius=0.4, start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "                   line_color=\"white\", color='color', source=plot_data)\n",
    "    p.axis.axis_label = None\n",
    "    p.axis.visible = False\n",
    "    p.grid.grid_line_color = None\n",
    "    p.outline_line_color = None\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(\"configs/stockslimited.csv\", \"\\t\", index_col=0, header=None).loc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_limit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [\n",
    "#     \"FFSFX\",\n",
    "    \"XLRE\",\n",
    "    \"XLV\",\n",
    "    \"FLSW\",\n",
    "#     \"ACLTX\",\n",
    "    \"FCOM\",\n",
    "#     \"TRZBX\",\n",
    "#     \"TILWX\",\n",
    "#     \"FITLX\",\n",
    "#     \"FNIDX\",\n",
    "#     \"FNDSX\",\n",
    "    \"SUSA\",\n",
    "    \"IQSU\", \n",
    "    \"USSG\",\n",
    "    \"SUSB\",\n",
    "    \"SNPE\",\n",
    "    \"SUSL\",\n",
    "    \"EAGG\",\n",
    "#     \"WSBFX\",\n",
    "#     \"NEXTX\",\n",
    "    \"CASH\",\n",
    "]\n",
    "\n",
    "tick_allowed = [\n",
    "#     True,#\"FFSFX\",\n",
    "    True,#\"XLRE\",\n",
    "    True,#\"XLV\",\n",
    "    True,#\"FLSW\",\n",
    "#     True,#\"ACLTX\",\n",
    "    True,#\"FCOM\",\n",
    "#     True,#\"TRZBX\",\n",
    "#     True,#\"TILWX\",\n",
    "#     True,#\"FITLX\",\n",
    "#     True,#\"FNIDX\",\n",
    "#     True,#\"FNDSX\",\n",
    "    True,#\"SUSA\",\n",
    "    True,#\"IQSU\", \n",
    "    True,#\"USSG\",\n",
    "    True,#\"SUSB\",\n",
    "    True,#\"SNPE\",\n",
    "    True,#\"SUSL\",\n",
    "    True,#\"EAGG\",\n",
    "#     False,#\"WSBFX\",\n",
    "#     False,#\"NEXTX\",\n",
    "    False,#\"CASH\",\n",
    "]\n",
    "\n",
    "tick_names =[ \n",
    "    yf.Ticker(ticker).info['longName'] for ticker in [\n",
    "#     \"FFSFX\",\n",
    "    \"XLRE\",\n",
    "    \"XLV\",\n",
    "    \"FLSW\",\n",
    "#     \"ACLTX\",\n",
    "    \"FCOM\",\n",
    "        \n",
    "#     \"TRZBX\",\n",
    "#     \"TILWX\",\n",
    "#     \"FITLX\",\n",
    "#     \"FNIDX\",\n",
    "#     \"FNDSX\",\n",
    "        \n",
    "    \"SUSA\",\n",
    "    \"IQSU\", \n",
    "    \"USSG\",\n",
    "    \"SUSB\",\n",
    "    \"SNPE\",\n",
    "    \"SUSL\",\n",
    "    \"EAGG\",\n",
    "        \n",
    "#     \"WSBFX\",\n",
    "#     \"NEXTX\",\n",
    "]] + [\"CASH\"]\n",
    "\n",
    "ticks_filtered = filterTickers(ticks, tick_allowed)\n",
    "tick_name_filtered = filterTickers(tick_names, tick_allowed)\n",
    "assert len(ticks) == len(tick_allowed)\n",
    "assert len(ticks) == len(tick_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XLRE',\n",
       " 'XLV',\n",
       " 'FLSW',\n",
       " 'FCOM',\n",
       " 'SUSA',\n",
       " 'IQSU',\n",
       " 'USSG',\n",
       " 'SUSB',\n",
       " 'SNPE',\n",
       " 'SUSL',\n",
       " 'EAGG',\n",
       " 'CASH']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Real Estate Select Sector SPDR Fund',\n",
       " 'Health Care Select Sector SPDR Fund',\n",
       " 'Franklin Templeton ETF Trust - Franklin FTSE Switzerland ETF',\n",
       " 'Fidelity MSCI Communication Services Index ETF',\n",
       " 'iShares Trust - iShares MSCI USA ESG Select ETF',\n",
       " 'IQ Candriam ESG US Equity ETF',\n",
       " 'Xtrackers MSCI USA ESG Leaders Equity ETF',\n",
       " 'iShares Trust - iShares ESG Aware 1-5 Year USD Corporate Bond ETF',\n",
       " 'Xtrackers S&P 500 ESG ETF',\n",
       " 'iShares Trust - iShares ESG MSCI USA Leaders ETF',\n",
       " 'iShares Trust - iShares ESG Aware U.S. Aggregate Bond ETF',\n",
       " 'CASH']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./configs/profiles\"\n",
    "FILE = open(path, 'r')\n",
    "profiles = FILE.readlines()\n",
    "FILE.close()\n",
    "profiles = [profile.strip() for profile in profiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.float_info.min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./configs/apikey\"\n",
    "FILE = open(path, 'r')\n",
    "api_key = FILE.readline()\n",
    "FILE.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://finnhub.io/api/v1/stock/candle?symbol=FFSFX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "2\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=ACLTX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "3\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=TRZBX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "4\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=TILWX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "5\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=FITLX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "6\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=FNIDX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "7\n",
      "https://finnhub.io/api/v1/stock/candle?symbol=FNDSX&resolution=D&from=959832000&to=1641216781&token=c6g2jhaad3id0r6gcvl0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "## MAIN BODY \n",
    "\n",
    "# Download historical data\n",
    "start = int(time.mktime(datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "end = int(time.mktime(datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "\n",
    "data_dict = dict()\n",
    "i = 1\n",
    "\n",
    "for stock in ticks_filtered:\n",
    "    if i % 20 == 0:\n",
    "        print(\"Sleeping for request limit\")\n",
    "        time.sleep(60)\n",
    "    \n",
    "#     querystring = {\"to\": end, \"symbol\": stock, \"from\": start, \"resolution\": 'D'}\n",
    "    querystring = f\"symbol={stock}&resolution=D&from={start}&to={end}&token={api_key}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\"GET\", url = (f\"https://finnhub.io/api/v1/stock/candle?{querystring}\"))\n",
    "        print(f\"https://finnhub.io/api/v1/stock/candle?{querystring}\")\n",
    "        \n",
    "        data = response.json()\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df = df.drop(columns=['s', 'h', 'l', 'o', 'v'])\n",
    "\n",
    "        # Output time zone: Universal Time Coordinated\n",
    "        df['time'] = [datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S') for x in df.t.values]\n",
    "\n",
    "    except:\n",
    "        raise ValueError(\"No data found for \" + stock)\n",
    "\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    # The download limit is 10 requests per minute\n",
    "            \n",
    "    data_dict[stock] = df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE PROCESS DATA TO A FRIENDLY FORMAT\n",
    "data_to_concat = []\n",
    "data_dict_new = {}\n",
    "for key in data_dict:\n",
    "    data_dict_new[key] = data_dict[key].rename(columns={\"c\": key})\n",
    "    data_dict_new[key]['time'] = pd.to_datetime(data_dict_new[key]['time']).dt.date\n",
    "    data_dict_new[key] = data_dict_new[key].set_index(\"time\")\n",
    "    data_to_concat.append(data_dict_new[key])\n",
    "    \n",
    "price_data = pd.concat(data_to_concat, axis=1)\n",
    "price_data = price_data.loc[:,~price_data.columns.duplicated()].drop(columns='t')\n",
    "price_data = price_data.sort_index()\n",
    "\n",
    "log_ret = np.log(price_data/price_data.shift(1))\n",
    "\n",
    "cov_mat = np.array(np.exp(log_ret.cov()*252)-1)\n",
    "log_ret_mean = np.array(log_ret.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFSFX</th>\n",
       "      <th>ACLTX</th>\n",
       "      <th>TRZBX</th>\n",
       "      <th>TILWX</th>\n",
       "      <th>FITLX</th>\n",
       "      <th>FNIDX</th>\n",
       "      <th>FNDSX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-05-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>14.09</td>\n",
       "      <td>24.62</td>\n",
       "      <td>180.86</td>\n",
       "      <td>24.34</td>\n",
       "      <td>21.31</td>\n",
       "      <td>13.18</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>14.08</td>\n",
       "      <td>24.50</td>\n",
       "      <td>179.82</td>\n",
       "      <td>24.20</td>\n",
       "      <td>21.28</td>\n",
       "      <td>13.19</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>14.08</td>\n",
       "      <td>24.49</td>\n",
       "      <td>179.32</td>\n",
       "      <td>24.18</td>\n",
       "      <td>21.33</td>\n",
       "      <td>13.19</td>\n",
       "      <td>10.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>13.38</td>\n",
       "      <td>24.43</td>\n",
       "      <td>179.24</td>\n",
       "      <td>24.16</td>\n",
       "      <td>21.26</td>\n",
       "      <td>13.22</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>13.37</td>\n",
       "      <td>24.29</td>\n",
       "      <td>177.68</td>\n",
       "      <td>24.04</td>\n",
       "      <td>21.20</td>\n",
       "      <td>13.22</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FFSFX  ACLTX   TRZBX  TILWX  FITLX  FNIDX  FNDSX\n",
       "2006-05-15    NaN   9.98     NaN    NaN    NaN    NaN    NaN\n",
       "2006-05-16    NaN   9.97     NaN    NaN    NaN    NaN    NaN\n",
       "2006-05-17    NaN   9.80     NaN    NaN    NaN    NaN    NaN\n",
       "2006-05-18    NaN   9.71     NaN    NaN    NaN    NaN    NaN\n",
       "2006-05-19    NaN   9.75     NaN    NaN    NaN    NaN    NaN\n",
       "...           ...    ...     ...    ...    ...    ...    ...\n",
       "2021-12-27  14.09  24.62  180.86  24.34  21.31  13.18  10.69\n",
       "2021-12-28  14.08  24.50  179.82  24.20  21.28  13.19  10.69\n",
       "2021-12-29  14.08  24.49  179.32  24.18  21.33  13.19  10.66\n",
       "2021-12-30  13.38  24.43  179.24  24.16  21.26  13.22  10.68\n",
       "2021-12-31  13.37  24.29  177.68  24.04  21.20  13.22  10.68\n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04052935, 0.0507208 , 0.04892488, 0.11489245, 0.04135304,\n",
       "       0.02973361, 0.00141597])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_data[\"ASML\"][-365:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\profiles\\Portfolio_Positions_Jan-03-2022.csv\n"
     ]
    }
   ],
   "source": [
    "list_of_files = glob.glob('.\\profiles\\*.csv')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "df = pd.read_csv(latest_file)\n",
    "df = df[~df.Description.isna() | (df.Symbol == \"Pending Activity\")]\n",
    "df = df[['Account Number', 'Symbol', 'Current Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFSFX</th>\n",
       "      <th>ACLTX</th>\n",
       "      <th>TRZBX</th>\n",
       "      <th>TILWX</th>\n",
       "      <th>FITLX</th>\n",
       "      <th>FNIDX</th>\n",
       "      <th>FNDSX</th>\n",
       "      <th>WSBFX</th>\n",
       "      <th>NEXTX</th>\n",
       "      <th>CASH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FFSFX  ACLTX  TRZBX  TILWX  FITLX  FNIDX  FNDSX  WSBFX  NEXTX  CASH\n",
       "***REMOVED***    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
       "***REMOVED***    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0\n",
       "***REMOVED***    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_makeup = pd.DataFrame(data = np.zeros((len(profiles), len(ticks))), \n",
    "                              index=profiles, \n",
    "                              columns=ticks)\n",
    "profile_makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFSFX</th>\n",
       "      <th>ACLTX</th>\n",
       "      <th>TRZBX</th>\n",
       "      <th>TILWX</th>\n",
       "      <th>FITLX</th>\n",
       "      <th>FNIDX</th>\n",
       "      <th>FNDSX</th>\n",
       "      <th>WSBFX</th>\n",
       "      <th>NEXTX</th>\n",
       "      <th>CASH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1131.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>***REMOVED***</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9280.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FFSFX  ACLTX  TRZBX  TILWX    FITLX  FNIDX   FNDSX  WSBFX  NEXTX  \\\n",
       "***REMOVED***    0.0    0.0    0.0    0.0     0.00    0.0    0.00    0.0    0.0   \n",
       "***REMOVED***    0.0    0.0    0.0    0.0     0.00    0.0    0.00    0.0    0.0   \n",
       "***REMOVED***    0.0    0.0    0.0    0.0  9280.89    0.0  159.58    0.0    0.0   \n",
       "\n",
       "              CASH  \n",
       "***REMOVED***  1131.77  \n",
       "***REMOVED***     0.01  \n",
       "***REMOVED***     0.00  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row_ in df.iterrows():\n",
    "    if row_[1][\"Symbol\"] in ticks and  row_[1][\"Account Number\"] in profiles:\n",
    "        profile_makeup.loc[row_[1][\"Account Number\"], row_[1][\"Symbol\"]] = float(row_[1][\"Current Value\"].replace(\"$\",\"\"))\n",
    "    elif row_[1][\"Account Number\"] in profiles:\n",
    "        profile_makeup.loc[row_[1][\"Account Number\"], \"CASH\"] += float(row_[1][\"Current Value\"].replace(\"$\",\"\"))\n",
    "profile_makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Inflation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": ['CUUR0000SA0'],\"startyear\":\"2020\", \"endyear\":\"2021\"})\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "json_data = json.loads(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(json_data['Results']['series'][0]['data'])\n",
    "df.head()\n",
    "values = df[\"value\"].to_numpy().astype(float)\n",
    "inflations = (values[:-12] - values[12:])/values[12:]  \n",
    "current_inflation = inflations[0]\n",
    "avg_inflation = inflations.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Max Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0800855194836447"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = lambda x: -get_sharpe(x)\n",
    "best_sharpe_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_sharpe(best_sharpe_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Risk Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03464361628251537"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = get_risk\n",
    "min_risk_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_risk(min_risk_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3389578885955929"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = lambda x: -get_risk(x)\n",
    "max_risk_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_risk(max_risk_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Return Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004533937733845361"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = lambda x: get_return(x)\n",
    "min_return_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_return(min_return_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1755137142115697"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = lambda x: -get_return(x)\n",
    "rts = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    )\n",
    "max_return_weights = rts.x\n",
    "get_return(max_return_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get List of Max Returns for Spread of risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_min = get_risk(min_risk_weights)\n",
    "risk_max = get_risk(max_return_weights)\n",
    "risks_count = 50\n",
    "risks_bot = np.linspace(risk_min, risk_max, risks_count, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Sharpe Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00899815559387207 seconds ---\n",
      "--- 0.013000249862670898 seconds ---\n",
      "--- 0.017998933792114258 seconds ---\n",
      "--- 0.020999431610107422 seconds ---\n",
      "--- 0.023999452590942383 seconds ---\n",
      "--- 0.027998924255371094 seconds ---\n",
      "--- 0.030999183654785156 seconds ---\n",
      "--- 0.03499913215637207 seconds ---\n",
      "--- 0.038999080657958984 seconds ---\n",
      "--- 0.042999267578125 seconds ---\n",
      "--- 0.046999454498291016 seconds ---\n",
      "--- 0.05199933052062988 seconds ---\n",
      "--- 0.054999351501464844 seconds ---\n",
      "--- 0.05899930000305176 seconds ---\n",
      "--- 0.06199908256530762 seconds ---\n",
      "--- 0.06499958038330078 seconds ---\n",
      "--- 0.0689992904663086 seconds ---\n",
      "--- 0.07199907302856445 seconds ---\n",
      "--- 0.07599949836730957 seconds ---\n",
      "--- 0.07899928092956543 seconds ---\n",
      "--- 0.0839986801147461 seconds ---\n",
      "--- 0.08799910545349121 seconds ---\n",
      "--- 0.09099841117858887 seconds ---\n",
      "--- 0.09499955177307129 seconds ---\n",
      "--- 0.0989997386932373 seconds ---\n",
      "--- 0.10299921035766602 seconds ---\n",
      "--- 0.10699915885925293 seconds ---\n",
      "--- 0.10999917984008789 seconds ---\n",
      "--- 0.11399960517883301 seconds ---\n",
      "--- 0.11799931526184082 seconds ---\n",
      "--- 0.12099933624267578 seconds ---\n",
      "--- 0.12399959564208984 seconds ---\n",
      "--- 0.12799906730651855 seconds ---\n",
      "--- 0.13199901580810547 seconds ---\n",
      "--- 0.13699936866760254 seconds ---\n",
      "--- 0.14099907875061035 seconds ---\n",
      "--- 0.14699912071228027 seconds ---\n",
      "--- 0.15199851989746094 seconds ---\n",
      "--- 0.15599966049194336 seconds ---\n",
      "--- 0.16099810600280762 seconds ---\n",
      "--- 0.16499829292297363 seconds ---\n",
      "--- 0.16899824142456055 seconds ---\n",
      "--- 0.17399930953979492 seconds ---\n",
      "--- 0.17799901962280273 seconds ---\n",
      "--- 0.18199920654296875 seconds ---\n",
      "--- 0.18699908256530762 seconds ---\n",
      "--- 0.1919996738433838 seconds ---\n",
      "--- 0.19699859619140625 seconds ---\n",
      "--- 0.20199942588806152 seconds ---\n",
      "--- 0.2069993019104004 seconds ---\n"
     ]
    }
   ],
   "source": [
    "best_weights_range = np.random.random(size=(risks_count, len(ticks_filtered))) \n",
    "start_time = time.time()\n",
    "for r in range(risks_count):\n",
    "    loss = lambda x: -get_return(x)\n",
    "    rts = minimize(\n",
    "          loss,\n",
    "          np.random.random(len(ticks_filtered)),\n",
    "          constraints=[\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "            {'type': 'ineq', 'fun': lambda w, risk=risks_bot[r]: -(get_risk(w) - risk)},\n",
    "          ],\n",
    "          bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "        )\n",
    "    best_weights_range[r, :] = rts.x\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 MAX\n",
      "0.1\n",
      "0.2 MAX\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "profiles_constraints = []\n",
    "profiles_losses = []\n",
    "for target in profiles_targets:\n",
    "    if target is None:\n",
    "        profiles_constraints.append(None)\n",
    "        profiles_losses.append(None)\n",
    "    else:\n",
    "        risk_t, return_t = target\n",
    "        print(risk_t, return_t)\n",
    "        if (risk_t == MAX or risk_t == MIN) and (return_t == MAX or return_t == MIN):\n",
    "            profiles_constraints.append(None)\n",
    "            if (risk_t == MAX) and (return_t == MAX):\n",
    "                profiles_losses.append(lambda x:-(get_return(x) * get_risk(x)))\n",
    "            elif (risk_t == MAX) and (return_t == MIN):\n",
    "                profiles_losses.append(lambda x: get_sharpe(x))\n",
    "            elif (risk_t == MIN) and (return_t == MAX):\n",
    "                profiles_losses.append(lambda x: -get_sharpe(x))\n",
    "            elif (risk_t == MIN) and (return_t == MIN):\n",
    "                profiles_losses.append(lambda x: get_return(x) * get_risk(x))\n",
    "        elif (risk_t == MAX or risk_t == MIN):\n",
    "            print(return_t)\n",
    "            profiles_constraints.append({'type': 'eq', 'fun': lambda x, return_t=return_t: (get_return(x) - return_t)}),\n",
    "            if risk_t == MAX:\n",
    "                profiles_losses.append(lambda x: -get_risk(x))\n",
    "            elif risk_t == MIN:\n",
    "                profiles_losses.append(lambda x: get_risk(x))\n",
    "        elif (return_t == MAX or return_t == MIN):\n",
    "            print(risk_t)\n",
    "            profiles_constraints.append({'type': 'eq', 'fun': lambda x, risk_t=risk_t: (get_risk(x) - risk_t)}),\n",
    "            if return_t == MAX:\n",
    "                profiles_losses.append(lambda x: -get_return(x))\n",
    "            elif return_t == MIN:\n",
    "                profiles_losses.append(lambda x: get_return(x))   \n",
    "        else:\n",
    "            profiles_constraints.append(None)\n",
    "            profiles_losses.append(lambda x,\n",
    "                                   return_t=return_t,\n",
    "                                   risk_t=risk_t: \n",
    "                                   np.abs(risk_t - get_risk(x)) * np.abs(return_t - get_return(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'type': 'eq', 'fun': <function <lambda> at 0x000001A7F06F4488>}\n",
      "True\n",
      "49\n",
      "0.1\n",
      "0.10000000000310492\n",
      "0.09502824687194877\n",
      "--- 0.005000114440917969 seconds ---\n",
      "1\n",
      "2\n",
      "{'type': 'eq', 'fun': <function <lambda> at 0x000001A7F06F4B70>}\n",
      "True\n",
      "49\n",
      "0.1\n",
      "0.20000002319550503\n",
      "0.17285298216362066\n",
      "--- 0.00500035285949707 seconds ---\n"
     ]
    }
   ],
   "source": [
    "b = 1000\n",
    "i = 1000\n",
    "lr = 0.015\n",
    "batch = [b]*len(profiles)\n",
    "iterations = [i]*len(profiles)\n",
    "LR=[lr]*len(profiles)\n",
    "\n",
    "LR[2]=0.005\n",
    "target_weights = []\n",
    "\n",
    "for i in range(len(profiles)):\n",
    "    print(i)\n",
    "    if profiles_targets[i] is not None:\n",
    "        \n",
    "        loss = profiles_losses[i]\n",
    "        start_time = time.time()\n",
    "        print(profiles_constraints[i])\n",
    "        rts = minimize(\n",
    "              loss,\n",
    "              np.random.random(len(ticks_filtered)),\n",
    "              constraints=[\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "                profiles_constraints[i],\n",
    "              ] if profiles_constraints[i] is not None else [\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},],\n",
    "              bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "            )\n",
    "\n",
    "        print(rts.success)\n",
    "        target_weights.append(np.concatenate([rts.x, [0,0,0]]))\n",
    "        print(r)\n",
    "        if profiles_constraints[i] is not None:\n",
    "            print(0.1)\n",
    "        print(get_risk(rts.x))\n",
    "        print(get_return(rts.x))\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        wts = profile_makeup.loc[profiles[i]].to_numpy()\n",
    "        target_weights.append(wts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Buys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "1131.77\n",
      "1.0\n",
      "[ 0.00000000e+00  6.13381451e-14  2.76256141e-13  0.00000000e+00\n",
      "  5.70821926e+02  7.96955062e-14  5.60948074e+02  0.00000000e+00\n",
      "  0.00000000e+00 -1.13177000e+03]\n",
      "=====================\n",
      "0.01\n",
      "0.01\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "=====================\n",
      "9440.47\n",
      "1.000000000000001\n",
      "[ 0.00000000e+00  1.01424194e-12  3.63654580e-12  0.00000000e+00\n",
      "  1.00860647e+01  4.19949160e-12 -1.00860647e+01  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "profile_changes = []\n",
    "for i in range(len(profiles)):\n",
    "    print(\"=====================\")\n",
    "    profile_sum = np.sum(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "    print(profile_sum)\n",
    "    target_sum = np.sum(target_weights[i])\n",
    "    print(target_sum)\n",
    "    changes = target_weights[i] * (profile_sum/target_sum) - profile_makeup.loc[profiles[i]].to_numpy()\n",
    "    print(changes)\n",
    "    profile_changes.append(changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT = 0.5\n",
    "LUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "color_list = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(ticks), endpoint=False)]\n",
    "color_list = [RGB(r*255,g*255,d*255) for r,g,d in color_list]\n",
    "color_list_accounts = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(profiles), endpoint=False)]\n",
    "color_list_accounts = [RGB(r*255,g*255,d*255) for r,g,d in color_list_accounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT = 0.5\n",
    "LUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(ticks), endpoint=False)]\n",
    "color_list = [RGB(r*255,g*255,d*255) for r,g,d in color_list]\n",
    "color_list_accounts = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(profiles), endpoint=False)]\n",
    "color_list_accounts = [RGB(r*255,g*255,d*255) for r,g,d in color_list_accounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Figure(id='6930', ...), Figure(id='6960', ...), Figure(id='6990', ...)]\n",
      "[Figure(id='7020', ...), Figure(id='7050', ...), Figure(id='7080', ...)]\n"
     ]
    }
   ],
   "source": [
    "source = ColumnDataSource(price_data)\n",
    "# ===== Setup Plot ====\n",
    "p = figure(\n",
    "    sizing_mode = \"stretch_both\", \n",
    "    title=\"Efficient frontier.\",\n",
    "    tools='box_zoom,wheel_zoom,reset', \n",
    "    toolbar_location='right',\n",
    "    x_range=(-0.25,1.0)\n",
    ")\n",
    "p.add_tools(CrosshairTool(line_alpha=1, line_color='lightgray', line_width=1))\n",
    "p.add_tools(HoverTool(tooltips=None))\n",
    "\n",
    "p.xaxis.axis_label = 'Volatility, or risk (standard deviation)'\n",
    "p.yaxis.axis_label = 'Annual return'\n",
    "p.xaxis[0].formatter = NumeralTickFormatter(format=\"0.0%\")\n",
    "p.yaxis[0].formatter = NumeralTickFormatter(format=\"0.0%\")\n",
    "# ===== Render Boundries ====\n",
    "risk_boundry = Span(location=get_risk(min_risk_weights),\n",
    "                    dimension='height', line_color='#3A5311',\n",
    "                    line_width=1)\n",
    "return_boundry = Span(location=get_return(max_return_weights), \n",
    "                      dimension='width', line_color='#3A5311',\n",
    "                      line_width=1)\n",
    "current_inf_boundry = Span(location=current_inflation, \n",
    "                      dimension='width', line_color='#03C04A',\n",
    "                           line_width=1)\n",
    "average_inf_boundry = Span(location=avg_inflation, \n",
    "                      dimension='width', line_color='#607D3B',\n",
    "                           line_width=1)\n",
    "p.renderers.extend([risk_boundry, return_boundry, current_inf_boundry, average_inf_boundry])\n",
    "# ===== Render Best Sharpe Line ====\n",
    "boundry =np.concatenate([\n",
    "    best_weights_range, \n",
    "])\n",
    "\n",
    "l = p.line(\n",
    "    get_risk_v(boundry),\n",
    "    get_return_v(boundry), \n",
    "    color=\"purple\",\n",
    "#     legend_label=\"Max Sharpe Line?\",\n",
    "    line_width=1)\n",
    "\n",
    "p.add_tools(HoverTool(renderers=[l], tooltips=[\n",
    "    ('Name', \"Max Sharpe Line\")\n",
    "]))\n",
    "# ===== Render Sharpe Lines ====\n",
    "p.line([0,get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "#        legend_label=\"Sharpe Of 1\",\n",
    "       color=\"#00B7EB\",line_width=1)\n",
    "p.line([0,0.5*get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "#        legend_label=\"Sharpe Of 2\",\n",
    "       color=\"#6495ED\",line_width=1)\n",
    "p.line([0,(1.0/3.0)*get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "#        legend_label=\"Sharpe Of 3\",\n",
    "       color=\"#007FFF\",line_width=1)\n",
    "# ====== Render Prices ======\n",
    "t = figure(\n",
    "    sizing_mode = \"stretch_both\", \n",
    "    title=\"Prices Over Time\",\n",
    "    tools='box_zoom,wheel_zoom,reset', \n",
    "    toolbar_location='right',\n",
    "    x_axis_type='datetime'\n",
    "#     x_range=(-0.25,1.0)\n",
    ")\n",
    "# timestamp_start = (datetime.combine(datepicker_start.value, datetime.min.time())\n",
    "#                         - datetime(1970, 1, 1)) / timedelta(seconds=1)\n",
    "# timestamp_end = (datetime.combine(datepicker_end.value, datetime.min.time())\n",
    "#                     - datetime(1970, 1, 1)) / timedelta(seconds=1)\n",
    "t.x_range.start = (datetime.now().timestamp() - 720*3600) * 1000  # Multiply by 1e3 as JS timestamp is in milliseconds\n",
    "t.x_range.end   = datetime.now().timestamp() * 1000  # Multiply by 1e3 as JS timestamp is in milliseconds\n",
    "\n",
    "\n",
    "t.add_tools(CrosshairTool(line_alpha=1, line_color='lightgray', line_width=1))\n",
    "t.add_tools(HoverTool(tooltips=None))\n",
    "\n",
    "t.xaxis.axis_label = 'Date'\n",
    "t.yaxis.axis_label = 'Price'\n",
    "t.xaxis[0].formatter = DatetimeTickFormatter(days=[\"%b %d, %Y\"])\n",
    "t.yaxis[0].formatter = NumeralTickFormatter(format=\"$0.0\")\n",
    "\n",
    "# ===== Plot prices =====\n",
    "range_ = 365*5\n",
    "source = ColumnDataSource((price_data-price_data[-range_:].mean())/price_data[-range_:].std())\n",
    "for i in range(len(ticks_filtered)):\n",
    "    t.line(x = \"index\", y=ticks_filtered[i],\n",
    "             source=source,\n",
    "             legend_label=ticks_filtered[i], \n",
    "             name=ticks_filtered[i], \n",
    "             color=color_list[i])\n",
    "\n",
    "# ===== Render Rebalance Buy Charts ====\n",
    "fidelity_buy_pies = []\n",
    "for i in range(len(profiles)):\n",
    "    \n",
    "    if profiles_targets[i] is not None:\n",
    "        wts = get_weights(profile_changes[i] * (profile_changes[i] > 0))\n",
    "    else:\n",
    "        wts = get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "    \n",
    "    cash = np.sum(profile_changes[i] * (profile_changes[i] > 0))\n",
    "\n",
    "    fidelity_buy_pies.append(\n",
    "        plot_portfolio_composition(ticks,\n",
    "                                   wts,\n",
    "                                   profiles_names[i] + \" Buy\",\n",
    "                                   color_list,\n",
    "                                   cash = cash))\n",
    "#     wts_filtered = filterTickers(wts_point, tick_allowed)\n",
    "\n",
    "print(fidelity_buy_pies)\n",
    "# ===== Render Rebalance Sell Pie Charts ====\n",
    "fidelity_sell_pies = []\n",
    "for i in range(len(profiles)):\n",
    "    \n",
    "    if profiles_targets[i] is not None:\n",
    "        wts = get_weights(-profile_changes[i] * (profile_changes[i] < 0))\n",
    "        \n",
    "    else:\n",
    "        wts = get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "    \n",
    "\n",
    "    cash = np.sum(-profile_changes[i] * (profile_changes[i] < 0))\n",
    "                            \n",
    "    fidelity_sell_pies.append(\n",
    "        plot_portfolio_composition(ticks,\n",
    "                                   wts,\n",
    "                                   profiles_names[i] + \" Sell\",\n",
    "                                   color_list,\n",
    "                                   cash = cash))\n",
    "#     wts_filtered = filterTickers(wts_point, tick_allowed)\n",
    "\n",
    "print(fidelity_sell_pies)\n",
    "# ===== Render Target Profile Pie Charts ====\n",
    "fidelity_targets = []\n",
    "renderers = []\n",
    "\n",
    "for i in range(len(target_weights)):\n",
    "    fidelity_targets.append(\n",
    "        plot_portfolio_composition(\n",
    "            (ticks if len(target_weights[i]) > len(ticks_filtered) else ticks_filtered),\n",
    "            get_weights(target_weights[i]),\n",
    "            profiles_names[i] + \" Target\",\n",
    "            color_list\n",
    "        ))\n",
    "    wts_filtered = filterTickers(target_weights[i], tick_allowed)\n",
    "    if np.sum(wts_filtered) != 0.0:\n",
    "        c = p.circle(get_risk(get_weights(wts_filtered)),\n",
    "                     get_return(get_weights(wts_filtered)),\n",
    "                     color=color_list_accounts[i],\n",
    "                     alpha=0.6,\n",
    "                     name=profiles_names[i] + \" Target\",\n",
    "                     legend_label=profiles_names[i] + \" Target\",\n",
    "                     size=15)\n",
    "        renderers.append(c)\n",
    "# ===== Render Existing Profile Pie Charts ====\n",
    "fidelity_pies = []\n",
    "tooltips = []\n",
    "for i in range(len(profiles)):\n",
    "    wts = get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "\n",
    "    fidelity_pies.append(\n",
    "        plot_portfolio_composition(ticks,\n",
    "                                   wts,\n",
    "                                   profiles_names[i],\n",
    "                                   color_list))\n",
    "    wts_filtered = filterTickers(wts, tick_allowed)\n",
    "    if np.sum(wts_filtered) != 0.0:\n",
    "        c = p.circle(get_risk(wts_filtered), \n",
    "                     get_return(wts_filtered), \n",
    "                     color=color_list_accounts[i], \n",
    "                     name=profiles_names[i],\n",
    "                     legend_label=profiles_names[i],\n",
    "                     size=15)\n",
    "        renderers.append(c)        \n",
    "\n",
    "tooltips.append(('Profile', \"$name\"))\n",
    "p.add_tools(HoverTool(renderers=renderers, tooltips=tooltips))\n",
    "# ===== Render Funds ====\n",
    "wts = np.eye(len(ticks_filtered))\n",
    "risks_ = get_risk_v(wts)\n",
    "returns_ = get_return_v(wts)\n",
    "colors = filterTickers(color_list, tick_allowed)\n",
    "renderers = []\n",
    "for i in range(len(ticks_filtered)):\n",
    "    c = p.circle(risks_[i],returns_[i],\n",
    "             color=color_list[i],\n",
    "             legend_label=ticks_filtered[i], \n",
    "             name=ticks_filtered[i], \n",
    "             size=10, alpha=0.8, )\n",
    "    renderers.append(c)\n",
    "p.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "    ('Tick', \"$name\")\n",
    "]))\n",
    "\n",
    "# ===== Adjusting Legend ====\n",
    "p.legend.location = \"top_left\"\n",
    "# p.legend.visible = False\n",
    "p.legend.click_policy=\"hide\"\n",
    "p.legend.__setattr__('label_text_font_size', '8pt')\n",
    "\n",
    "\n",
    "t.legend.location = \"top_left\"\n",
    "# t.legend.visible = False\n",
    "t.legend.click_policy=\"hide\"\n",
    "t.legend.__setattr__('label_text_font_size', '8pt')\n",
    "# ===== Create dashboard and open new window to show results ====\n",
    "layout_ = row([ \n",
    "        column([\n",
    "            p,\n",
    "            t,\n",
    "        ], sizing_mode = \"stretch_both\"),\n",
    "    column([\n",
    "        row(fidelity_pies,\n",
    "               sizing_mode = \"stretch_height\"), \n",
    "        row(fidelity_targets\n",
    "               , sizing_mode = \"stretch_height\"),\n",
    "        row(fidelity_sell_pies\n",
    "               , sizing_mode = \"stretch_height\"),\n",
    "        row(fidelity_buy_pies\n",
    "               , sizing_mode = \"stretch_height\"),\n",
    "    ])\n",
    "    ],width = 1350, sizing_mode = \"stretch_height\")\n",
    "    \n",
    "show(layout_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
