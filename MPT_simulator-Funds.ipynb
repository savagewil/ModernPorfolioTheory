{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## IMPORT NECESSARY LIBRARIES \n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as npg\n",
    "from autograd import grad, elementwise_grad as e_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, CrosshairTool, HoverTool, NumeralTickFormatter, Span\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column, row, gridplot, layout\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.colors import RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime,date\n",
    "import math\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import bankroll\n",
    "import colorsys\n",
    "# import cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, minimize_scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw, self.v_dw = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, t, w, dw):\n",
    "        self.m_dw = np.add(np.multiply(self.beta1,self.m_dw),np.multiply((1-self.beta1), dw))\n",
    "\n",
    "        self.v_dw = np.add(np.multiply(self.beta2, self.v_dw), np.multiply((1-self.beta2),np.square(dw)))\n",
    "\n",
    "        m_dw_corr = np.divide(self.m_dw,np.subtract((1+self.epsilon),np.power(self.beta1,t)))\n",
    "        v_dw_corr = np.divide(self.v_dw,np.subtract((1+self.epsilon),np.power(self.beta2,t)))\n",
    "\n",
    "        w = np.subtract(w, np.multiply(self.eta, np.divide(m_dw_corr, np.add(np.sqrt(v_dw_corr), self.epsilon))))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.sum(x)\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def tanh_refined(x):\n",
    "    return (np.tanh(x)+1.0)/2.0\n",
    "\n",
    "def get_weights(wts):\n",
    "#     wts = sigmoid(wts)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts)\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_v(wts):\n",
    "#     wts = sigmoid(wts)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts, axis=1, keepdims=True)\n",
    "    return wts\n",
    "\n",
    "def get_return_v(wts):\n",
    "    wts = get_weights_v(wts)\n",
    "    port_ret = npg.sum(log_ret_mean * wts, axis=1)\n",
    "    port_ret = npg.exp(npg.multiply(port_ret, 252)) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk_v(wts):\n",
    "    wts = get_weights_v(wts)\n",
    "    port_sd = npg.sqrt(npg.sum(wts * npg.dot(wts, cov_mat.T), axis=1))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe_v(wts):\n",
    "    port_ret = get_return_v(wts)\n",
    "    port_sd = get_risk_v(wts)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr\n",
    "\n",
    "def get_loss_v(risk_target=None, return_target=None, sharpe_target=None):\n",
    "    weight = 1.0e3\n",
    "    if risk_target is not None and return_target is not None:\n",
    "        return lambda x: (weight*(npg.square(risk_target - get_risk_v(x)))+\n",
    "                          (npg.square(return_target - get_return_v(x))))/(weight + 1.0)\n",
    "    elif risk_target is not None and sharpe_target is not None:\n",
    "        return lambda x: ((weight*npg.square(risk_target - get_risk_v(x)))+\n",
    "                          (npg.square((sharpe_target - get_sharpe_v(x))/2.0)))/(weight + 1.0)\n",
    "    elif risk_target is not None:\n",
    "        return lambda x: ((weight*npg.square(risk_target - get_risk_v(x))) - get_return_v(x))/(weight + 1.0)\n",
    "    elif return_target is not None:\n",
    "        return lambda x: ((weight*npg.square(return_target - get_return_v(x))) + get_risk_v(x))/(weight + 1.0)\n",
    "    return lambda x: npg.negative(get_sharpe_v(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterTickers(ticks, tick_allowed):\n",
    "    return [tick for tick, allowed in zip(ticks, tick_allowed) if allowed]\n",
    "\n",
    "def get_return(wts):\n",
    "    wts = np.array(wts)\n",
    "#     wts = get_weights(wts)\n",
    "    port_ret = npg.sum(log_ret_mean * wts)\n",
    "    port_ret = np.exp(port_ret*252) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk(wts):\n",
    "    wts = np.array(wts)\n",
    "#     wts = get_weights(wts)\n",
    "    port_sd = npg.sqrt(npg.dot(wts.T, npg.dot(cov_mat, wts)))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe(wts):\n",
    "    port_ret = get_return(wts)\n",
    "    port_sd = get_risk(wts)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr\n",
    "\n",
    "def get_loss(risk_target=None, return_target=None, sharpe_target=None):\n",
    "    weight = 1.0e3\n",
    "    if risk_target is not None and return_target is not None:\n",
    "        return lambda x: (weight*(npg.square(risk_target - get_risk(x)))+\n",
    "                          (npg.square(return_target - get_return(x))))/(weight + 1.0)\n",
    "    elif risk_target is not None and sharpe_target is not None:\n",
    "        return lambda x: ((weight*npg.square(risk_target - get_risk(x)))+\n",
    "                          (npg.square((sharpe_target - get_sharpe(x))/2.0)))/(weight + 1.0)\n",
    "    elif risk_target is not None:\n",
    "        return lambda x: ((weight*npg.square(risk_target - get_risk(x))) - get_return(x))/(weight + 1.0)\n",
    "    elif return_target is not None:\n",
    "        return lambda x: ((weight*npg.square(return_target - get_return(x))) + get_risk(x))/(weight + 1.0)\n",
    "    return lambda x: npg.negative(get_sharpe(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For adding cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_ratio(wts_1, wts_2, ratio):\n",
    "#     wts = sigmoid(wts)\n",
    "    wts_1 = np.array(wts_1)\n",
    "    wts_2 = np.array(wts_2)\n",
    "    wts = wts_1 * ratio + wts_2 * (1.0 - ratio)\n",
    "    wts = npg.maximum(0.0, wts)\n",
    "    if npg.sum(wts) != 0:\n",
    "        wts = wts/npg.sum(wts)\n",
    "    return wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filterTickers(ticks, tick_allowed):\n",
    "    return [tick for tick, allowed in zip(ticks, tick_allowed) if allowed]\n",
    "\n",
    "def get_return_ratio(wts_1,wts_2,ratio):\n",
    "    wts = get_weights_ratio(wts_1,wts_2,ratio)\n",
    "    port_ret = npg.sum(log_ret_mean * wts)\n",
    "    port_ret = np.exp(port_ret*252) - 1\n",
    "    return port_ret\n",
    "    \n",
    "def get_risk_ratio(wts_1,wts_2,ratio):\n",
    "    wts = get_weights_ratio(wts_1,wts_2,ratio)\n",
    "    port_sd = npg.sqrt(npg.dot(wts.T, npg.dot(cov_mat, wts)))\n",
    "    return port_sd\n",
    "\n",
    "def get_sharpe_ratio(wts_1,wts_2,ratio):\n",
    "    port_ret = get_return_ratio(wts_1,wts_2,ratio)\n",
    "    port_sd = get_risk_ratio(wts_1,wts_2,ratio)\n",
    "    sr = port_ret / port_sd\n",
    "    return sr\n",
    "\n",
    "# def get_loss(risk_target=None, return_target=None, sharpe_target=None):\n",
    "#     weight = 1.0e3\n",
    "#     if risk_target is not None and return_target is not None:\n",
    "#         return lambda x: (weight*(npg.square(risk_target - get_risk(x)))+\n",
    "#                           (npg.square(return_target - get_return(x))))/(weight + 1.0)\n",
    "#     elif risk_target is not None and sharpe_target is not None:\n",
    "#         return lambda x: ((weight*npg.square(risk_target - get_risk(x)))+\n",
    "#                           (npg.square((sharpe_target - get_sharpe(x))/2.0)))/(weight + 1.0)\n",
    "#     elif risk_target is not None:\n",
    "#         return lambda x: ((weight*npg.square(risk_target - get_risk(x))) - get_return(x))/(weight + 1.0)\n",
    "#     elif return_target is not None:\n",
    "#         return lambda x: ((weight*npg.square(return_target - get_return(x))) + get_risk(x))/(weight + 1.0)\n",
    "#     return lambda x: npg.negative(get_sharpe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_gd_weights(weights_size, loss_fun, batch, iterations, LR, scorings, initial=None):\n",
    "    # Optimize weights using gradient descent.\n",
    "    if initial is not None:\n",
    "        best_weights = get_weights(initial) + np.random.uniform(size=weights_size)\n",
    "    else:\n",
    "        best_weights = np.random.uniform(size=weights_size)\n",
    "    training_gradient_fun = grad(loss_fun)\n",
    "    scores = np.zeros((len(scorings), batch, iterations))\n",
    "    for b in range(batch):\n",
    "        if initial is not None:\n",
    "            wts = get_weights(initial) + np.random.uniform(size=weights_size)\n",
    "        else:\n",
    "            wts = np.random.uniform(size=weights_size)\n",
    "#         wts = np.random.uniform(size=weights_size)\n",
    "        for i in range(iterations):\n",
    "            wts = wts - training_gradient_fun(wts) * LR\n",
    "            for s in range(len(scorings)):\n",
    "                scores[s, b, i] = scorings[s](wts)\n",
    "        if loss_fun(wts) < loss_fun(best_weights):\n",
    "            best_weights = wts\n",
    "    return best_weights, scores\n",
    "\n",
    "def calculate_weights(weights_size, loss_fun_v, batch, iterations, LR, scorings, initial=None):\n",
    "    adam = AdamOptim(eta=LR)\n",
    "    training_gradient_fun_v = e_grad(loss_fun_v)\n",
    "    scores = np.zeros((len(scorings), batch, iterations))\n",
    "    wts = np.random.uniform(size=(batch, weights_size))*4\n",
    "    print(wts.shape)\n",
    "    for i in range(iterations):\n",
    "        dw = training_gradient_fun_v(wts)\n",
    "        wts = adam.update(i+1,wts, dw)\n",
    "        for s in range(len(scorings)):\n",
    "            scores[s, :, i] = scorings[s](wts)\n",
    "    best_weights = wts[np.argmin(loss_fun_v(wts)),:]\n",
    "    return best_weights, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_vs_return(risk, returns, risk_title=\"Risk\", return_title=\"Return\"):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].plot(risk.T)\n",
    "    ax[0].set_title(risk_title)\n",
    "    ax[1].plot(returns.T)\n",
    "    ax[1].set_title(return_title)\n",
    "    \n",
    "    ax[0].set_ylabel('Risk')\n",
    "    ax[0].set_xlabel('Iteration')\n",
    "    ax[1].set_ylabel('Return')\n",
    "    ax[1].set_xlabel('Iteration')\n",
    "    plt.show()\n",
    "\n",
    "    # Portfolio composition. Min variance, max SR, max return\n",
    "def plot_portfolio_composition(ticks, weights, plot_name, color_list):\n",
    "#     print(ticks)\n",
    "    x = dict()\n",
    "    c = dict()\n",
    "    for i in range(len(ticks)):\n",
    "        if weights[i] >= 1.0:\n",
    "            x[ticks[i]] = weights[i]\n",
    "            c[ticks[i]] = color_list[i]\n",
    "            x[ticks[i]+\" \"] = weights[i]\n",
    "            c[ticks[i]+\" \"] = color_list[i]\n",
    "        elif weights[i] > 0.001:\n",
    "            x[ticks[i]] = weights[i]\n",
    "            c[ticks[i]] = color_list[i]\n",
    "\n",
    "    plot_data = pd.Series(x).reset_index(name='value').rename(columns={'index': 'stock'})\n",
    "    plot_data['angle'] = plot_data['value'] / plot_data['value'].sum() * 2 * math.pi\n",
    "    \n",
    "    plot_data['color'] = c.values()\n",
    "    \n",
    "#     print(plot_data)\n",
    "#     print()\n",
    "    p = figure(width=50, height=50, title=plot_name, toolbar_location=None,sizing_mode = \"scale_height\",\n",
    "                      tools=\"hover\", tooltips=\"@stock: @value{%0.1f}\", x_range=(-0.5,0.5))\n",
    "    p.wedge(x=0, y=1, radius=0.4, start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "                   line_color=\"white\", color='color', source=plot_data)\n",
    "    p.axis.axis_label = None\n",
    "    p.axis.visible = False\n",
    "    p.grid.grid_line_color = None\n",
    "    p.outline_line_color = None\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_profiles = 5000\n",
    "inflation_rate = 0.06\n",
    "\n",
    "start_date = '2000-06-01 00:00:00'\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(\"configs/stocks.csv\", \"\\t\", index_col=0, header=None).loc[:,:2]\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_limit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = [\n",
    "    \"XLRE\",\n",
    "    \"XLV\",\n",
    "    \"FLSW\",\n",
    "    \"ACLTX\",\n",
    "    \"FCOM\",\n",
    "    \"TRZBX\",\n",
    "    \"TILWX\",\n",
    "    \"FITLX\",\n",
    "    \"FNIDX\",\n",
    "    \"FNDSX\",\n",
    "    \"SUSA\",\n",
    "    \"IQSU\", \n",
    "    \"USSG\",\n",
    "    \"SUSB\",\n",
    "    \"SNPE\",\n",
    "    \"SUSL\",\n",
    "    \"EAGG\",\n",
    "    \"WSBFX\",\n",
    "    \"NEXTX\",\n",
    "    \"CASH\",\n",
    "]\n",
    "\n",
    "tick_allowed = [\n",
    "    True,#\"XLRE\",\n",
    "    True,#\"XLV\",\n",
    "    True,#\"FLSW\",\n",
    "    True,#\"ACLTX\",\n",
    "    True,#\"FCOM\",\n",
    "    True,#\"TRZBX\",\n",
    "    True,#\"TILWX\",\n",
    "    True,#\"FITLX\",\n",
    "    True,#\"FNIDX\",\n",
    "    True,#\"FNDSX\",\n",
    "    True,#\"SUSA\",\n",
    "    True,#\"IQSU\", \n",
    "    True,#\"USSG\",\n",
    "    True,#\"SUSB\",\n",
    "    True,#\"SNPE\",\n",
    "    True,#\"SUSL\",\n",
    "    True,#\"EAGG\",\n",
    "    False,#\"WSBFX\",\n",
    "    False,#\"NEXTX\",\n",
    "    False,#\"CASH\",\n",
    "]\n",
    "\n",
    "tick_names = [ \n",
    "    yf.Ticker(ticker).info['longName'] for ticker in [\n",
    "    \"XLRE\",\n",
    "    \"XLV\",\n",
    "    \"FLSW\",\n",
    "    \"ACLTX\",\n",
    "    \"FCOM\",\n",
    "    \"TRZBX\",\n",
    "    \"TILWX\",\n",
    "    \"FITLX\",\n",
    "    \"FNIDX\",\n",
    "    \"FNDSX\",\n",
    "    \"SUSA\",\n",
    "    \"IQSU\", \n",
    "    \"USSG\",\n",
    "    \"SUSB\",\n",
    "    \"SNPE\",\n",
    "    \"SUSL\",\n",
    "    \"EAGG\",\n",
    "    \"WSBFX\",\n",
    "    \"NEXTX\",\n",
    "]] + [\"CASH\"]\n",
    "\n",
    "ticks_filtered = filterTickers(ticks, tick_allowed)\n",
    "tick_name_filtered = filterTickers(tick_names, tick_allowed)\n",
    "assert len(ticks) == len(tick_allowed)\n",
    "assert len(ticks) == len(tick_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./configs/profiles\"\n",
    "FILE = open(path, 'r')\n",
    "profiles = FILE.readlines()\n",
    "FILE.close()\n",
    "profiles = [profile.strip() for profile in profiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_names = [\n",
    "    \"Roth IRA\",\n",
    "    \"Investment Account\",\n",
    "    \"Amazon \",\n",
    "    \"Cash Account\",\n",
    "]\n",
    "profiles_targets = [\n",
    "    lambda x:-get_return(x),\n",
    "    None,\n",
    "    get_loss(),\n",
    "    None\n",
    "]\n",
    "profiles_constraints = [\n",
    "    {'type': 'eq', 'fun': lambda w: (get_risk(w) - 0.10)},\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"./configs/apikey\"\n",
    "FILE = open(path, 'r')\n",
    "api_key = FILE.readline()\n",
    "FILE.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## MAIN BODY \n",
    "\n",
    "# Download historical data\n",
    "start = int(time.mktime(datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "end = int(time.mktime(datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "\n",
    "data_dict = dict()\n",
    "i = 1\n",
    "\n",
    "for stock in ticks_filtered:\n",
    "    if i % 20 == 0:\n",
    "        print(\"Sleeping for request limit\")\n",
    "        time.sleep(60)\n",
    "    \n",
    "#     querystring = {\"to\": end, \"symbol\": stock, \"from\": start, \"resolution\": 'D'}\n",
    "    querystring = f\"symbol={stock}&resolution=D&from={start}&to={end}&token={api_key}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\"GET\", url = (f\"https://finnhub.io/api/v1/stock/candle?{querystring}\"))\n",
    "        print(f\"https://finnhub.io/api/v1/stock/candle?{querystring}\")\n",
    "        \n",
    "        data = response.json()\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df = df.drop(columns=['s', 'h', 'l', 'o', 'v'])\n",
    "\n",
    "        # Output time zone: Universal Time Coordinated\n",
    "        df['time'] = [datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S') for x in df.t.values]\n",
    "\n",
    "    except:\n",
    "        raise ValueError(\"No data found for \" + stock)\n",
    "\n",
    "    i += 1\n",
    "    print(i)\n",
    "\n",
    "    # The download limit is 10 requests per minute\n",
    "            \n",
    "    data_dict[stock] = df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE PROCESS DATA TO A FRIENDLY FORMAT\n",
    "data_to_concat = []\n",
    "data_dict_new = {}\n",
    "for key in data_dict:\n",
    "    data_dict_new[key] = data_dict[key].rename(columns={\"c\": key})\n",
    "    data_dict_new[key]['time'] = pd.to_datetime(data_dict_new[key]['time']).dt.date\n",
    "    data_dict_new[key] = data_dict_new[key].set_index(\"time\")\n",
    "    data_to_concat.append(data_dict_new[key])\n",
    "    \n",
    "price_data = pd.concat(data_to_concat, axis=1)\n",
    "price_data = price_data.loc[:,~price_data.columns.duplicated()].drop(columns='t')\n",
    "price_data = price_data.sort_index()\n",
    "\n",
    "log_ret = np.log(price_data/price_data.shift(1))\n",
    "\n",
    "cov_mat = np.array(np.exp(log_ret.cov()*252)-1)\n",
    "log_ret_mean = np.array(log_ret.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_files = glob.glob('.\\profiles\\*.csv')\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "df = pd.read_csv(latest_file)\n",
    "df = df[~df.Description.isna()]\n",
    "df = df[['Account Number', 'Symbol', 'Current Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_makeup = pd.DataFrame(data = np.zeros((len(profiles), len(ticks))), \n",
    "                              index=profiles, \n",
    "                              columns=ticks)\n",
    "profile_makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_ in df.iterrows():\n",
    "    if row_[1][\"Symbol\"] in ticks and  row_[1][\"Account Number\"] in profiles:\n",
    "        profile_makeup.loc[row_[1][\"Account Number\"], row_[1][\"Symbol\"]] = float(row_[1][\"Current Value\"][1:])\n",
    "    elif row_[1][\"Account Number\"] in profiles:\n",
    "        profile_makeup.loc[row_[1][\"Account Number\"], \"CASH\"] = float(row_[1][\"Current Value\"][1:])\n",
    "profile_makeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Inflation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-type': 'application/json'}\n",
    "data = json.dumps({\"seriesid\": ['CUUR0000SA0'],\"startyear\":\"2020\", \"endyear\":\"2021\"})\n",
    "p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "json_data = json.loads(p.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(json_data['Results']['series'][0]['data'])\n",
    "df.head()\n",
    "values = df[\"value\"].to_numpy().astype(float)\n",
    "inflations = (values[:-12] - values[12:])/values[12:]  \n",
    "current_inflation = inflations[0]\n",
    "avg_inflation = inflations.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Max Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss()\n",
    "best_sharpe_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_sharpe(best_sharpe_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=0.05\n",
    "\n",
    "# start_time = time.time()\n",
    "# best_sharpe_weights, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                         get_loss_v(), batch,\n",
    "#                                                         iterations, LR,\n",
    "#                                                         [get_risk_v,get_return_v])\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "# get_sharpe(best_sharpe_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Risk Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_risk\n",
    "min_risk_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_risk(min_risk_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Get Min Risk\n",
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=1.0\n",
    "\n",
    "# start_time = time.time()\n",
    "# min_risk_weights, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                 get_risk_v, batch,\n",
    "#                                                 iterations, LR, \n",
    "#                                                 [get_risk_v, get_return_v])\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# # least_risk_weights, loss = get_gd_weights_adam(len(ticks_filtered), get_risk, batch, iterations, LR, [get_risk])\n",
    "# # loss = loss[0,:,:]\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "\n",
    "# get_risk(best_sharpe_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda x: -get_risk(x)\n",
    "max_risk_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_risk(max_risk_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Get Max Risk\n",
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=1.0\n",
    "\n",
    "# loss_fun = lambda x: npg.negative(get_risk_v(x))\n",
    "\n",
    "# start_time = time.time()\n",
    "# max_risk_weights, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                 loss_fun, batch,\n",
    "#                                                 iterations, LR, \n",
    "#                                                 [get_risk_v, get_return_v])\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# # least_risk_weights, loss = get_gd_weights_adam(len(ticks_filtered), get_risk, batch, iterations, LR, [get_risk])\n",
    "# # loss = loss[0,:,:]\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "# get_risk(max_risk_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Return Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda x: get_return(x)\n",
    "min_return_weights = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    ).x\n",
    "get_return(min_return_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Min Return\n",
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=1.0\n",
    "\n",
    "# start_time = time.time()\n",
    "# min_return_weights, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                  get_return_v, batch,\n",
    "#                                                  iterations, LR,\n",
    "#                                                  [get_risk_v,get_return_v])\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# # most_return_weights, loss = get_gd_weights_adam(len(ticks_filtered), \n",
    "# #                                            lambda x: -get_return(x),\n",
    "# #                                            batch, iterations,\n",
    "# #                                            LR, [get_risk])\n",
    "# # loss = loss[0,:,:]\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "# get_risk(min_return_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda x: -get_return(x)\n",
    "rts = minimize(\n",
    "      loss,\n",
    "      np.random.random(len(ticks_filtered)),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "    )\n",
    "max_return_weights = rts.x\n",
    "get_return(max_return_weights)\n",
    "rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Get Max Return\n",
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=1.0\n",
    "# loss_fun = lambda x: npg.negative(get_return_v(x))\n",
    "\n",
    "# start_time = time.time()\n",
    "# max_return_weights, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                  loss_fun, batch,\n",
    "#                                                  iterations, LR,\n",
    "#                                                  [get_risk_v,get_return_v])\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# # most_return_weights, loss = get_gd_weights_adam(len(ticks_filtered), \n",
    "# #                                            lambda x: -get_return(x),\n",
    "# #                                            batch, iterations,\n",
    "# #                                            LR, [get_risk])\n",
    "# # loss = loss[0,:,:]\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "# get_return(max_return_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get List of Max Returns for Spread of risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_min = get_risk(min_risk_weights)\n",
    "risk_max = get_risk(max_return_weights)\n",
    "risks_count = 50\n",
    "risks_bot = np.linspace(risk_min, risk_max, risks_count, True)\n",
    "risks_top = np.flip(np.linspace(risk_max, risk_min, risks_count, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1000\n",
    "i = 4000\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# risks[34:-13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Sharpe Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = [b]*risks_count\n",
    "iterations = [i]*risks_count\n",
    "LR=np.array([lr]*risks_count)\n",
    "# LR[34:-13] *= 2\n",
    "# LR = LR*(1.0 + 50*np.abs(0.25 - risks))\n",
    "# LR[-3]*=10\n",
    "\n",
    "best_weights_range = np.random.random(size=(risks_count, len(ticks_filtered))) \n",
    "start_time = time.time()\n",
    "for r in range(risks_count):\n",
    "    loss = lambda x: -get_return(x)\n",
    "#     loss = get_loss(risk_target=risks[r])\n",
    "#     \n",
    "#     if risks[r] < get_risk(max_return_weights):\n",
    "    rts = minimize(\n",
    "          loss,\n",
    "          np.random.random(len(ticks_filtered)),\n",
    "          constraints=[\n",
    "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "            {'type': 'ineq', 'fun': lambda w: -(get_risk(w) - risks_bot[r])},\n",
    "#             {'type': 'ineq', 'fun': lambda w: (risks_top[r] - get_risk(w))},\n",
    "          ],\n",
    "          bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "        )\n",
    "#     else:\n",
    "#         rts = minimize(\n",
    "#               loss,\n",
    "#               np.random.random(len(ticks_filtered)),\n",
    "#               constraints=[\n",
    "#                 {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "#                 {'type': 'ineq', 'fun': lambda w: -(risks[r] - get_risk(w))},\n",
    "#               ],\n",
    "#               bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "#             )\n",
    "        \n",
    "#     print(rts.success)\n",
    "    best_weights_range[r, :] = rts.x\n",
    "#     print(r)\n",
    "#     print(risks[r])\n",
    "#     print(get_risk(best_weights_range[r, :]))\n",
    "#     print(get_return(best_weights_range[r, :]))\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#     plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:], risk_title=\"Risk %f\"%risks[r])\n",
    "\n",
    "# max_return_weights = minimize(\n",
    "#       loss,\n",
    "#       np.random.random(len(ticks_filtered)),\n",
    "#       constraints=[\n",
    "#         {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "#       ],\n",
    "#       bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "#     ).x\n",
    "# get_return(max_return_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return_min = get_return(min_return_weights)\n",
    "# return_max = get_return(max_return_weights)\n",
    "# returns_count = 50\n",
    "# returns_bot = np.linspace(return_min, return_max, returns_count, False)\n",
    "# returns_top = np.flip(np.linspace(return_max, return_min , returns_count, False))\n",
    "\n",
    "# batch = [b]*risks_count\n",
    "# iterations = [i]*risks_count\n",
    "# LR=np.array([lr]*risks_count)\n",
    "# # LR[34:-13] *= 2\n",
    "# # LR = LR*(1.0 + 50*np.abs(0.25 - risks))\n",
    "# # LR[-3]*=10\n",
    "\n",
    "# returns_weights_range = np.random.random(size=(returns_count, len(ticks_filtered))) \n",
    "# start_time = time.time()\n",
    "# for r in range(risks_count):\n",
    "#     loss = lambda x: get_risk(x)\n",
    "# #     loss = get_loss(risk_target=risks[r])\n",
    "# #     \n",
    "# #     if risks[r] < get_risk(max_return_weights):\n",
    "#     rts = minimize(\n",
    "#           loss,\n",
    "#           np.random.random(len(ticks_filtered)),\n",
    "#           constraints=[\n",
    "#             {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "#             {'type': 'ineq', 'fun': lambda w: (get_return(w) - returns_top[r])},\n",
    "#             {'type': 'ineq', 'fun': lambda w: (returns_top[r] - get_return(w))},\n",
    "#           ],\n",
    "#           bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "#         )\n",
    "# #     else:\n",
    "# #         rts = minimize(\n",
    "# #               loss,\n",
    "# #               np.random.random(len(ticks_filtered)),\n",
    "# #               constraints=[\n",
    "# #                 {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "# #                 {'type': 'ineq', 'fun': lambda w: -(risks[r] - get_risk(w))},\n",
    "# #               ],\n",
    "# #               bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "# #             )\n",
    "        \n",
    "# #     print(rts.success)\n",
    "#     returns_weights_range[r, :] = rts.x\n",
    "# #     print(r)\n",
    "# #     print(returns_bot[r],\"-\", returns_top[r])\n",
    "# #     print(get_risk(returns_weights_range[r, :]))\n",
    "# #     print(get_return(returns_weights_range[r, :]))\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "# #     plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:], risk_title=\"Risk %f\"%risks[r])\n",
    "\n",
    "# # max_return_weights = minimize(\n",
    "# #       loss,\n",
    "# #       np.random.random(len(ticks_filtered)),\n",
    "# #       constraints=[\n",
    "# #         {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "# #       ],\n",
    "# #       bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "# #     ).x\n",
    "# # get_return(max_return_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch = [b]*risks_count\n",
    "# iterations = [i]*risks_count\n",
    "# LR=np.array([lr]*risks_count)\n",
    "# # LR[34:-13] *= 2\n",
    "# # LR = LR*(1.0 + 50*np.abs(0.25 - risks))\n",
    "# # LR[-3]*=10\n",
    "\n",
    "# best_weights_range = np.random.random(size=(risks_count, len(ticks_filtered))) \n",
    "# for r in range(risks_count):\n",
    "# # for r in range(34, 50-13):\n",
    "#     start_time = time.time()\n",
    "#     best_weights_range[r, :], scoring = calculate_weights(len(ticks_filtered), \n",
    "#                                                                     get_loss_v(risk_target=risks[r]), \n",
    "#                                                                     batch[r],\n",
    "#                                                                     iterations[r],\n",
    "#                                                                     LR[r],\n",
    "#                                                                     [get_risk_v,get_return_v])\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#     plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:], risk_title=\"Risk %f\"%risks[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Sharpe Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch = [b]*risks_count\n",
    "# iterations = [i]*risks_count\n",
    "# LR=np.array([lr]*risks_count)\n",
    "# # LR = LR*(1.0 + 50*np.abs(0.07 - risks))\n",
    "# # LR[-3]*=10\n",
    "\n",
    "# worst_weights_range = np.random.uniform(size=(risks_count, len(ticks_filtered))) \n",
    "# for r in range(risks_count):\n",
    "#     start_time = time.time()\n",
    "#     worst_weights_range[r, :], scoring = calculate_weights(len(ticks_filtered), \n",
    "#                                                                     get_loss_v(risk_target=risks[r], return_target=0.0), \n",
    "#                                                                     batch[r],\n",
    "#                                                                     iterations[r],\n",
    "#                                                                     LR[r],\n",
    "#                                                                     [get_risk_v,get_return_v])\n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#     plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:], risk_title=\"Risk %f\"%risks[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile to match inflation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch = 1000\n",
    "# iterations = 1000\n",
    "# LR=0.01\n",
    "\n",
    "# start_time = time.time()\n",
    "# inflation_weights, scoring = calculate_weights(len(ticks_filtered), \n",
    "#                                            get_loss_v(return_target=avg_inflation),\n",
    "#                                            batch, iterations,\n",
    "#                                            LR, [get_risk_v,get_return_v])\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:], return_title=\"Return %f\"%avg_inflation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = 1000\n",
    "i = 1000\n",
    "lr = 0.015\n",
    "batch = [b]*len(profiles)\n",
    "iterations = [i]*len(profiles)\n",
    "LR=[lr]*len(profiles)\n",
    "\n",
    "# batch[2] = 10\n",
    "# iterations[2] = 200\n",
    "LR[2]=0.005\n",
    "target_weights = []\n",
    "\n",
    "for i in range(len(profiles)):\n",
    "    if profiles_targets[i] is not None:\n",
    "        \n",
    "        loss = profiles_targets[i]\n",
    "        start_time = time.time()\n",
    "        print(profiles_constraints[i])\n",
    "        rts = minimize(\n",
    "              loss,\n",
    "              np.random.random(len(ticks_filtered)),\n",
    "              constraints=[\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "                profiles_constraints[i],\n",
    "              ] if profiles_constraints[i] is not None else [\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},],\n",
    "              bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "            )\n",
    "\n",
    "        print(rts.success)\n",
    "        target_weights.append(rts.x)\n",
    "        print(r)\n",
    "        if profiles_constraints[i] is not None:\n",
    "            print(0.1)\n",
    "        print(get_risk(rts.x))\n",
    "        print(get_return(rts.x))\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#         wts = profile_makeup.loc[profiles[i]].to_numpy()[:-1]\n",
    "#         print(i)\n",
    "#         target_weights_, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                     profiles_targets[i],\n",
    "#                                                     batch[i], iterations[i],\n",
    "#                                                     LR[i], [get_risk_v,get_return_v],\n",
    "#                                                     initial = filterTickers(wts, tick_allowed))\n",
    "#         target_weights.append(target_weights_)\n",
    "# #         risk,returns = scoring[0,:,:],scoring[1,:,:]\n",
    "#         plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        wts = profile_makeup.loc[profiles[i]].to_numpy()\n",
    "        target_weights.append(wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_targets_ratio = [\n",
    "    lambda x:-get_return_ratio(filterTickers(get_weights(profile_makeup.loc[profiles[0]].to_numpy()), tick_allowed),\n",
    "                               x,\n",
    "                               (np.sum(filterTickers(get_weights(profile_makeup.loc[profiles[0]].to_numpy()), tick_allowed))/\n",
    "                                np.sum(get_weights(profile_makeup.loc[profiles[0]].to_numpy())))),\n",
    "    None,\n",
    "    lambda x:-get_sharpe_ratio(filterTickers(get_weights(profile_makeup.loc[profiles[2]].to_numpy()), tick_allowed),\n",
    "                               x,\n",
    "                               (np.sum(filterTickers(get_weights(profile_makeup.loc[profiles[2]].to_numpy()), tick_allowed))/\n",
    "                                np.sum(get_weights(profile_makeup.loc[profiles[2]].to_numpy())))),\n",
    "    None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_constraints_ratio = [\n",
    "    {'type': 'eq', 'fun': lambda w: (get_risk_ratio(filterTickers(get_weights(profile_makeup.loc[profiles[0]].to_numpy()), tick_allowed),\n",
    "                               w,\n",
    "                               (np.sum(filterTickers(get_weights(profile_makeup.loc[profiles[0]].to_numpy()), tick_allowed))/\n",
    "                                np.sum(get_weights(profile_makeup.loc[profiles[0]].to_numpy())))) - 0.10)},\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(filterTickers(get_weights(profile_makeup.loc[profiles[0]].to_numpy()), tick_allowed))/\n",
    "                                np.sum(get_weights(profile_makeup.loc[profiles[0]].to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = 1000\n",
    "i = 1000\n",
    "lr = 0.015\n",
    "batch = [b]*len(profiles)\n",
    "iterations = [i]*len(profiles)\n",
    "LR=[lr]*len(profiles)\n",
    "\n",
    "# batch[2] = 10\n",
    "# iterations[2] = 200\n",
    "LR[2]=0.005\n",
    "target_weights_adding = []\n",
    "\n",
    "for i in range(len(profiles)):\n",
    "    if profiles_targets_ratio[i] is not None:\n",
    "        \n",
    "        loss = profiles_targets_ratio[i]\n",
    "        start_time = time.time()\n",
    "        print(profiles_constraints[i])\n",
    "        rts = minimize(\n",
    "              loss,\n",
    "              np.random.random(len(ticks_filtered)),\n",
    "              constraints=[\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "                profiles_constraints_ratio[i],\n",
    "              ] if profiles_constraints_ratio[i] is not None else [\n",
    "                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},],\n",
    "              bounds=[(0., 1.) for i in range(len(ticks_filtered))]\n",
    "            )\n",
    "\n",
    "        print(rts.success)\n",
    "        target_weights_adding.append(rts.x)\n",
    "        print(r)\n",
    "        if profiles_constraints_ratio[i] is not None:\n",
    "            print(0.1)\n",
    "        print(get_risk(rts.x))\n",
    "        print(get_return(rts.x))\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "#         wts = profile_makeup.loc[profiles[i]].to_numpy()[:-1]\n",
    "#         print(i)\n",
    "#         target_weights_, scoring = calculate_weights(len(ticks_filtered),\n",
    "#                                                     profiles_targets_ratio[i],\n",
    "#                                                     batch[i], iterations[i],\n",
    "#                                                     LR[i], [get_risk_v,get_return_v],\n",
    "#                                                     initial = filterTickers(wts, tick_allowed))\n",
    "#         target_weights.append(target_weights_)\n",
    "# #         risk,returns = scoring[0,:,:],scoring[1,:,:]\n",
    "#         plot_risk_vs_return(scoring[0,:,:],scoring[1,:,:])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        wts = profile_makeup.loc[profiles[i]].to_numpy()\n",
    "        target_weights_adding.append(np.zeros_like(wts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT = 0.5\n",
    "LUM = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "color_list = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(ticks), endpoint=False)]\n",
    "color_list = [RGB(r*255,g*255,d*255) for r,g,d in color_list]\n",
    "color_list_accounts = [colorsys.hls_to_rgb(h, LUM, SAT) for h in np.linspace(0.0, 1.0, len(profiles), endpoint=False)]\n",
    "color_list_accounts = [RGB(r*255,g*255,d*255) for r,g,d in color_list_accounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## PLOTS\n",
    "\n",
    "# ===== Setup Plot ====\n",
    "p = figure(\n",
    "    sizing_mode = \"stretch_both\", \n",
    "    title=\"Efficient frontier. Simulations: \" + str(num_profiles),\n",
    "    tools='box_zoom,wheel_zoom,reset', \n",
    "    toolbar_location='above',\n",
    ")\n",
    "p.add_tools(CrosshairTool(line_alpha=1, line_color='lightgray', line_width=1))\n",
    "p.add_tools(HoverTool(tooltips=None))\n",
    "\n",
    "p.xaxis.axis_label = 'Volatility, or risk (standard deviation)'\n",
    "p.yaxis.axis_label = 'Annual return'\n",
    "p.xaxis[0].formatter = NumeralTickFormatter(format=\"0.0%\")\n",
    "p.yaxis[0].formatter = NumeralTickFormatter(format=\"0.0%\")\n",
    "\n",
    "# ===== Render Funds ====\n",
    "wts = np.eye(len(ticks_filtered))\n",
    "risks_ = get_risk_v(wts)\n",
    "returns_ = get_return_v(wts)\n",
    "colors = filterTickers(color_list, tick_allowed)\n",
    "renderers = []\n",
    "for i in range(len(ticks_filtered)):\n",
    "    c = p.circle(risks_[i],returns_[i],\n",
    "             color=colors[i],\n",
    "             legend_label=ticks_filtered[i], \n",
    "             name=ticks_filtered[i], \n",
    "             size=10, alpha=0.8, )\n",
    "    renderers.append(c)\n",
    "p.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "    ('Tick', \"$name\")\n",
    "]))\n",
    "\n",
    "# ===== Render Boundries ====\n",
    "risk_boundry = Span(location=get_risk(min_risk_weights),\n",
    "                    dimension='height', line_color='#3A5311',\n",
    "                    line_width=1)\n",
    "return_boundry = Span(location=get_return(max_return_weights), \n",
    "                      dimension='width', line_color='#3A5311',\n",
    "                      line_width=1)\n",
    "current_inf_boundry = Span(location=current_inflation, \n",
    "                      dimension='width', line_color='#03C04A',\n",
    "                           line_width=1)\n",
    "average_inf_boundry = Span(location=avg_inflation, \n",
    "                      dimension='width', line_color='#607D3B',\n",
    "                           line_width=1)\n",
    "p.renderers.extend([risk_boundry, return_boundry, current_inf_boundry, average_inf_boundry])\n",
    "\n",
    "# ===== Render Best Sharpe Line ====\n",
    "boundry =np.concatenate([\n",
    "#     np.reshape(min_risk_weights,(1, len(min_risk_weights))),\n",
    "    best_weights_range, \n",
    "#     np.reshape(max_risk_weights,(1, len(max_risk_weights))),\n",
    "])\n",
    "\n",
    "# c = p.circle(get_risk_v(boundry),\n",
    "#          get_return_v(boundry),\n",
    "#          color=\"#\", legend_label=\"Max Sharpe Line\", size=4)\n",
    "l = p.line(\n",
    "    get_risk_v(boundry),\n",
    "    get_return_v(boundry), \n",
    "    color=\"purple\",\n",
    "    legend_label=\"Max Sharpe Line?\"\n",
    "    ,line_width=1)\n",
    "\n",
    "p.add_tools(HoverTool(renderers=[l], tooltips=[\n",
    "    ('Name', \"Max Sharpe Line\")\n",
    "]))\n",
    "\n",
    "# returns_weights_range\n",
    "\n",
    "# # ===== Render Worst Sharpe Line ====\n",
    "# boundry = np.concatenate([\n",
    "#     np.reshape(min_risk_weights,(1, len(min_risk_weights))),\n",
    "#     worst_weights_range, \n",
    "#     np.reshape(max_risk_weights,(1, len(max_risk_weights))),\n",
    "# ])\n",
    "\n",
    "# p.circle(get_risk_v(boundry),\n",
    "#          get_return_v(boundry),\n",
    "#          color=\"maroon\", legend_label=\"Max Sharpe Line\", size=4)\n",
    "# p.line(get_risk_v(boundry),\n",
    "#        get_return_v(boundry), \n",
    "#        color=\"maroon\", line_width=2)\n",
    "\n",
    "\n",
    "# ===== Render Sharpe Lines ====\n",
    "p.line([0,get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "       color=\"blue\",line_width=1)\n",
    "p.line([0,0.5*get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "       color=\"blue\",line_width=1)\n",
    "p.line([0,(1.0/3.0)*get_return(max_return_weights)],\n",
    "       [0,get_return(max_return_weights)],\n",
    "       color=\"blue\",line_width=1)\n",
    "\n",
    "# ===== Render Existing Profile Pie Charts ====\n",
    "fidelity_buy_pies = []\n",
    "for i in range(len(profiles)):\n",
    "    if profiles_targets_ratio[i] is not None:\n",
    "        wts = get_weights(target_weights_adding[i])\n",
    "        wts_point = get_weights_ratio((get_weights(profile_makeup.loc[profiles[i]].to_numpy()) \n",
    "                                 if len(target_weights_adding[i]) > len(ticks_filtered) else\n",
    "                                 filterTickers(get_weights(profile_makeup.loc[profiles[i]].to_numpy()), tick_allowed)),\n",
    "                                target_weights_adding[i],\n",
    "                                (np.sum(filterTickers(get_weights(profile_makeup.loc[profiles[i]].to_numpy()), tick_allowed))/\n",
    "                                 np.sum(get_weights(profile_makeup.loc[profiles[i]].to_numpy()))))\n",
    "    else:\n",
    "#         print(\"Elsed\")\n",
    "        wts = get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "                            \n",
    "#                              get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "#     print(\"wts\",wts)\n",
    "    fidelity_buy_pies.append(\n",
    "        plot_portfolio_composition((ticks if len(target_weights_adding[i]) > len(ticks_filtered) else ticks_filtered),\n",
    "                                   wts,\n",
    "                                   profiles_names[i] + \" Buy\",\n",
    "                                   color_list))\n",
    "    wts_filtered = filterTickers(wts_point, tick_allowed)\n",
    "    if len(target_weights_adding[i]) == len(ticks_filtered):\n",
    "        c = p.circle(get_risk(wts_point),\n",
    "                     get_return(wts_point),\n",
    "                     alpha=0.6,\n",
    "                     color=color_list_accounts[i], \n",
    "                     name=profiles_names[i] + \" Buy\",\n",
    "                     legend_label=profiles_names[i] + \" Buy\", size=15)\n",
    "        renderers.append(c)\n",
    "#         tooltips.append(('Profile', profiles_names[i]))\n",
    "\n",
    "print(fidelity_buy_pies)\n",
    "# p.add_tools(HoverTool(renderers=renderers, tooltips=tooltips))\n",
    "# ===== Render Target Profile Pie Charts ====\n",
    "fidelity_targets = []\n",
    "# renderers = []\n",
    "# tooltips = []\n",
    "for i in range(len(target_weights)):\n",
    "    fidelity_targets.append(\n",
    "        plot_portfolio_composition(\n",
    "            (ticks if len(target_weights[i]) > len(ticks_filtered) else ticks_filtered),\n",
    "            get_weights(target_weights[i]),\n",
    "            profiles_names[i] + \" Target\",\n",
    "            color_list\n",
    "        ))\n",
    "    if len(target_weights[i]) == len(ticks_filtered):\n",
    "        c = p.circle(get_risk(get_weights(target_weights[i])),\n",
    "                     get_return(get_weights(target_weights[i])),\n",
    "                     color=color_list_accounts[i],\n",
    "                     alpha=0.6,\n",
    "                     name=profiles_names[i] + \" Target\",\n",
    "                     legend_label=profiles_names[i] + \" Target\",\n",
    "                     size=15)\n",
    "        renderers.append(c)\n",
    "#         p.add_tools(HoverTool(renderers=[c], tooltips=[\n",
    "#             ('Profile', profiles_names[i] + \" Target\")\n",
    "#         ]))\n",
    "# ===== Render Existing Profile Pie Charts ====\n",
    "fidelity_pies = []\n",
    "renderers = []\n",
    "tooltips = []\n",
    "for i in range(len(profiles)):\n",
    "    wts = get_weights(profile_makeup.loc[profiles[i]].to_numpy())\n",
    "#     print(\"wts\",wts)\n",
    "    fidelity_pies.append(\n",
    "        plot_portfolio_composition(ticks,\n",
    "                                   wts,\n",
    "                                   profiles_names[i],\n",
    "                                   color_list))\n",
    "    wts_filtered = filterTickers(wts, tick_allowed)\n",
    "    if np.sum(wts_filtered) != 0.0:\n",
    "        c = p.circle(get_risk(wts_filtered), \n",
    "                     get_return(wts_filtered), \n",
    "                     color=color_list_accounts[i], \n",
    "                     name=profiles_names[i],\n",
    "                     legend_label=profiles_names[i],\n",
    "                     size=15)\n",
    "        renderers.append(c)        \n",
    "\n",
    "tooltips.append(('Profile', \"$name\"))\n",
    "p.add_tools(HoverTool(renderers=renderers, tooltips=tooltips))\n",
    "# ===== Adjusting Legend ====\n",
    "p.legend.location = \"top_left\"\n",
    "p.legend.visible = False\n",
    "\n",
    "\n",
    "# ===== Create dashboard and open new window to show results ====\n",
    "layout_ = row([ \n",
    "        column([\n",
    "            p\n",
    "        ], sizing_mode = \"stretch_both\"),\n",
    "        column(fidelity_pies,\n",
    "               sizing_mode = \"stretch_height\"), \n",
    "        column(fidelity_targets\n",
    "               , sizing_mode = \"stretch_height\"),\n",
    "        column(fidelity_buy_pies\n",
    "               , sizing_mode = \"stretch_height\"),\n",
    "    ],width = 1300, sizing_mode = \"stretch_height\")\n",
    "    \n",
    "show(layout_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
